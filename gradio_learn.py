import os
os.environ.pop('SSL_CERT_FILE', None)
os.environ.pop('SSL_CERT_DIR', None)

import gradio as gr
import pandas as pd
import numpy as np
import os
import re
import json
import datetime
from langchain_community.llms import Ollama
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_community.vectorstores import Qdrant
from langchain_core.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain
from langchain.chains import RetrievalQA
from qdrant_client import QdrantClient
from qdrant_client.http import models
import pickle
import time
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import io
import base64

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("rag_app.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
def get_embeddings():
    """OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        embeddings = OpenAIEmbeddings(
            model="text-embedding-ada-002",
            openai_api_key="secret"  # ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”
        )
        return embeddings
    except Exception as e:
        logger.error(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# Qdrant í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
def setup_qdrant_client(collection_name="product_recommendations"):
    """Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # ë¡œì»¬ Qdrant ì¸ìŠ¤í„´ìŠ¤ì— ì—°ê²°
        client = QdrantClient(":memory:")  # ë©”ëª¨ë¦¬ ëª¨ë“œ (ì‹¤ì œ ë°°í¬ ì‹œ ì„œë²„ URL ì‚¬ìš©)
        
        # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        collections = client.get_collections().collections
        collection_exists = any(collection.name == collection_name for collection in collections)
        
        # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not collection_exists:
            client.create_collection(
                collection_name=collection_name,
                vectors_config=models.VectorParams(
                    size=1536,  # text-embedding-ada-002ì˜ ì°¨ì›
                    distance=models.Distance.COSINE
                )
            )
            logger.info(f"Qdrant ì»¬ë ‰ì…˜ '{collection_name}'ì´(ê°€) ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return client
    except Exception as e:
        logger.error(f"Qdrant ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ìƒí’ˆ ë°ì´í„° ë¡œë“œ
def load_product_data(file_path="narosu_db_final.csv", excel_path="narosu_db_final.xlsx"):
    """ì „ì²˜ë¦¬ëœ ìƒí’ˆ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # CSV íŒŒì¼ ì‹œë„
        if os.path.exists(file_path):
            df = pd.read_csv(file_path, encoding='utf-8')
            logger.info(f"CSV ìƒí’ˆ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œì˜ ìƒí’ˆ")
            return df
        
        # CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ Excel íŒŒì¼ ì‹œë„
        elif os.path.exists(excel_path):
            logger.info(f"CSV íŒŒì¼ ì—†ìŒ, Excel íŒŒì¼ '{excel_path}'ë¡œë“œ ì‹œë„ ì¤‘...")
            df = pd.read_excel(excel_path)
            
            # Excelì—ì„œ ë¡œë“œí•œ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (í–¥í›„ ì‚¬ìš©ì„ ìœ„í•´)
            df.to_csv(file_path, index=False, encoding='utf-8')
            logger.info(f"Excel ìƒí’ˆ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œì˜ ìƒí’ˆ")
            return df
        
        else:
            logger.error(f"ìƒí’ˆ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: CSV('{file_path}') ë˜ëŠ” Excel('{excel_path}')")
            return None
    except Exception as e:
        logger.error(f"ìƒí’ˆ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# ì„ë² ë”© ë°ì´í„° ë¡œë“œ
# ì„ë² ë”© ë°ì´í„° ë¡œë“œ
def load_embeddings(embeddings_dir="embeddings_checkpoints"):
    """ì €ì¥ëœ ì„ë² ë”© ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    all_embeddings = []
    all_product_ids = []
    
    try:
        # embeddings_checkpoint.pkl íŒŒì¼ í™•ì¸
        checkpoint_file = os.path.join(embeddings_dir, "embeddings_checkpoint.pkl")
        
        if os.path.exists(checkpoint_file):
            with open(checkpoint_file, 'rb') as f:
                checkpoint_data = pickle.load(f)
                
                # checkpoint êµ¬ì¡° í™•ì¸ ë° ì„ë² ë”© ì¶”ì¶œ
                if isinstance(checkpoint_data, dict) and 'embeddings' in checkpoint_data:
                    all_embeddings = checkpoint_data['embeddings']
                    logger.info(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ {len(all_embeddings)}ê°œ ì„ë² ë”© ë¡œë“œë¨")
                    
                    # ìƒí’ˆ ID ìƒì„± ë˜ëŠ” ì¶”ì¶œ
                    if 'last_index' in checkpoint_data:
                        last_index = checkpoint_data['last_index']
                        all_product_ids = [str(i) for i in range(last_index + 1)]
                        logger.info(f"ìƒí’ˆ ID ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(all_product_ids)}ê°œ")
                else:
                    # êµ¬ì¡°ê°€ ë‹¤ë¥¸ ê²½ìš° ì§ì ‘ ì‚¬ìš©
                    all_embeddings = checkpoint_data
                    all_product_ids = [str(i) for i in range(len(all_embeddings))]
                    logger.info(f"ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(all_embeddings)}ê°œ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)")
                
        # ê¸°ì¡´ ë°©ì‹ë„ ì‹œë„ (ì²­í¬ íŒŒì¼ í™•ì¸)
        elif os.path.exists(embeddings_dir):
            chunk_files = [f for f in os.listdir(embeddings_dir) if f.startswith("embeddings_chunk_") and f.endswith(".pkl")]
            
            if chunk_files:
                for chunk_file in chunk_files:
                    file_path = os.path.join(embeddings_dir, chunk_file)
                    with open(file_path, 'rb') as f:
                        chunk_data = pickle.load(f)
                        if isinstance(chunk_data, dict) and 'embeddings' in chunk_data and 'product_ids' in chunk_data:
                            all_embeddings.extend(chunk_data['embeddings'])
                            all_product_ids.extend(chunk_data['product_ids'])
                
                logger.info(f"ì²­í¬ íŒŒì¼ì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(all_embeddings)}ê°œ")
            else:
                logger.warning(f"ì„ë² ë”© ë””ë ‰í† ë¦¬ '{embeddings_dir}'ì— ì„ë² ë”© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.warning(f"ì„ë² ë”© ë””ë ‰í† ë¦¬ '{embeddings_dir}'ì™€ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return all_embeddings, all_product_ids
    except Exception as e:
        logger.error(f"ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return [], []

# ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
def init_vector_store(client, collection_name, product_data, embeddings_data, product_ids, embeddings_model):
    """ë²¡í„° ì €ì¥ì†Œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        # Qdrant ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        vector_store = Qdrant(
            client=client,
            collection_name=collection_name,
            embeddings=embeddings_model
        )
        
        # ë²¡í„° ì €ì¥ì†Œì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        if client.count(collection_name=collection_name).count == 0 and embeddings_data:
            logger.info("ë²¡í„° ì €ì¥ì†Œì— ë°ì´í„° ì¶”ê°€ ì¤‘...")
            
            # ì„ë² ë”©ê³¼ ìƒí’ˆ ë°ì´í„° ë§¤í•‘
            documents = []
            points = []
            
            for i, (emb, product_id) in enumerate(zip(embeddings_data, product_ids)):
                # í•´ë‹¹ ìƒí’ˆ IDì˜ ë°ì´í„° ì°¾ê¸°
                product_row = product_data[product_data['ìƒí’ˆì½”ë“œ'] == product_id] if 'ìƒí’ˆì½”ë“œ' in product_data.columns else None
                
                if product_row is not None and not product_row.empty:
                    product = product_row.iloc[0]
                    
                    # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                    metadata = {
                        "ìƒí’ˆì½”ë“œ": str(product.get("ìƒí’ˆì½”ë“œ", "")),
                        "ì›ë³¸ìƒí’ˆëª…": str(product.get("ì›ë³¸ìƒí’ˆëª…", "")),
                        "ì¹´í…Œê³ ë¦¬ëª…": str(product.get("ì¹´í…Œê³ ë¦¬ëª…", "")),
                        "ê°€ê²©": int(product.get("ì˜¤ë„ˆí´ëœíŒë§¤ê°€", 0)),
                        "í‚¤ì›Œë“œ": str(product.get("í‚¤ì›Œë“œ", "")),
                        "ì´ë¯¸ì§€URL": str(product.get("ì´ë¯¸ì§€ëŒ€", ""))
                    }
                    
                    # Document ê°ì²´ ìƒì„±
                    doc = Document(
                        page_content=str(product.get("í†µí•©_í…ìŠ¤íŠ¸", "")),
                        metadata=metadata
                    )
                    documents.append(doc)
                    
                    # Qdrant í¬ì¸íŠ¸ ìƒì„±
                    point = models.PointStruct(
                        id=i,
                        vector=emb,
                        payload=metadata
                    )
                    points.append(point)
            
            # ë°°ì¹˜ ì—…ë¡œë“œ (ëŒ€ëŸ‰ ë°ì´í„°ì˜ ê²½ìš° ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì—…ë¡œë“œ)
            chunk_size = 1000  # í•œ ë²ˆì— ì—…ë¡œë“œí•  í¬ì¸íŠ¸ ìˆ˜
            for i in range(0, len(points), chunk_size):
                chunk = points[i:i + chunk_size]
                client.upsert(
                    collection_name=collection_name,
                    points=chunk
                )
                logger.info(f"ì²­í¬ {i//chunk_size + 1}: {len(chunk)}ê°œì˜ í¬ì¸íŠ¸ ì¶”ê°€ ì™„ë£Œ")
            
            logger.info(f"ì´ {len(points)}ê°œì˜ í¬ì¸íŠ¸ë¥¼ Qdrantì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
        
        return vector_store
    except Exception as e:
        logger.error(f"ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# LLaMA ëª¨ë¸ ì´ˆê¸°í™”
def init_llm():
    """LLaMA 3.1 ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        # Ollamaë¥¼ í†µí•´ LLaMA 3.1 ëª¨ë¸ì— ì ‘ê·¼
        # Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨: ollama run llama3.1
        llm = Ollama(model="llama3.1")
        return llm
    except Exception as e:
        logger.error(f"LLM ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
def init_rag_pipeline(vector_store, llm):
    """RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if vector_store is None or llm is None:
        logger.error("ë²¡í„° ì €ì¥ì†Œ ë˜ëŠ” LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)
        prompt_template = """
        ë‹¹ì‹ ì€ ìƒí’ˆ ì¶”ì²œ ë° ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        # ì§€ì¹¨
        - ì§ˆë¬¸ì— ê´€ë ¨ëœ ìƒí’ˆì„ ì§ì ‘ì ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        - ì‚¬ìš©ìì˜ ì˜ë„ì™€ ì„ í˜¸ë„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.
        - ê°€ê²©, í’ˆì§ˆ, íŠ¹ì§• ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        - ì¶”ì²œ ì´ìœ ë¥¼ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        - ìƒí’ˆì— ëŒ€í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
        
        # ì‚¬ìš©ì ì§ˆë¬¸
        {question}
        
        # ê´€ë ¨ ìƒí’ˆ ì •ë³´
        {context}
        
        # ë‹µë³€
        """
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["question", "context"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„± (ê²€ìƒ‰ ê°œìˆ˜ ì¦ê°€)
        retriever = vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 8}  # ìƒìœ„ 8ê°œ ê²°ê³¼ ê²€ìƒ‰ (ë” ë§ì€ í›„ë³´ ê²€ìƒ‰)
        )
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        return qa_chain
    except Exception as e:
        logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì±„íŒ… ê¸°ë¡ ì €ì¥ ë° ì‘ë‹µ ìƒì„±
class ChatHistory:
    def __init__(self):
        self.messages = []
        self.system_prompt = """
        ë‹¹ì‹ ì€ ìƒí’ˆ ì¶”ì²œ ë° ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ê´€ë ¨ ìƒí’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        ìƒí’ˆì— ê´€í•œ ì§ˆë¬¸ì´ë©´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´, ê·¸ ì‚¬ì‹¤ì„ ì†”ì§í•˜ê²Œ ì•Œë ¤ì£¼ì„¸ìš”.
        ì¼ë°˜ì ì¸ ëŒ€í™”ì—ë„ ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”.
        """
        self.search_history = []  # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
        
    def add_message(self, role, content):
        """ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        self.messages.append({"role": role, "content": content})
        
    def add_search_result(self, query, results):
        """ê²€ìƒ‰ ê¸°ë¡ì„ ì €ì¥í•©ë‹ˆë‹¤."""
        self.search_history.append({
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "query": query,
            "num_results": len(results),
            "top_categories": self._extract_top_categories(results)
        })
    
    def _extract_top_categories(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        categories = {}
        for doc in results:
            category = doc.metadata.get("ì¹´í…Œê³ ë¦¬ëª…", "").split(" > ")[0]
            if category:
                categories[category] = categories.get(category, 0) + 1
        
        # ìƒìœ„ 3ê°œ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        top_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)[:3]
        return [cat for cat, count in top_categories]
    
    def get_messages(self):
        """ëª¨ë“  ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.messages
    
    def get_display_messages(self):
        """Gradio ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ìš© ë©”ì‹œì§€ í¬ë§·ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return [(msg["content"], None) if msg["role"] == "user" else (None, msg["content"]) 
                for msg in self.messages]
    
    def format_prompt(self, query):
        """LLMì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        prompt = self.system_prompt + "\n\n"
        
        # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ)
        context_messages = self.messages[-10:]
        for msg in context_messages:
            if msg["role"] == "user":
                prompt += f"ì‚¬ìš©ì: {msg['content']}\n"
            else:
                prompt += f"ì‹œìŠ¤í…œ: {msg['content']}\n"
        
        # í˜„ì¬ ì¿¼ë¦¬ ì¶”ê°€
        prompt += f"ì‚¬ìš©ì: {query}\nì‹œìŠ¤í…œ: "
        
        return prompt
    
    def get_search_analytics(self):
        """ê²€ìƒ‰ ë¶„ì„ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.search_history:
            return "ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
            
        # ì¹´í…Œê³ ë¦¬ í†µê³„
        all_categories = []
        for search in self.search_history:
            all_categories.extend(search["top_categories"])
        
        category_counts = {}
        for category in all_categories:
            category_counts[category] = category_counts.get(category, 0) + 1
            
        # ê²€ìƒ‰ì–´ ë¶„ì„
        search_queries = [search["query"] for search in self.search_history]
        
        return {
            "total_searches": len(self.search_history),
            "top_categories": sorted(category_counts.items(), key=lambda x: x[1], reverse=True),
            "search_queries": search_queries
        }

# ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… í•¨ìˆ˜
def format_search_results(result):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    answer = result['result']
    source_docs = result.get('source_documents', [])
    
    # ê²€ìƒ‰ëœ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
    products_info = []
    for i, doc in enumerate(source_docs, 1):
        metadata = doc.metadata
        product_name = metadata.get('ì›ë³¸ìƒí’ˆëª…', 'ìƒí’ˆëª… ì—†ìŒ')
        category = metadata.get('ì¹´í…Œê³ ë¦¬ëª…', 'ì¹´í…Œê³ ë¦¬ ì—†ìŒ')
        price = metadata.get('ê°€ê²©', 0)
        product_id = metadata.get('ìƒí’ˆì½”ë“œ', '')
        keywords = metadata.get('í‚¤ì›Œë“œ', '')
        image_url = metadata.get('ì´ë¯¸ì§€URL', '')
        
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° HTML ì´ë¯¸ì§€ íƒœê·¸ ì¶”ê°€
        image_html = ""
        if image_url:
            image_html = f'\n<img src="{image_url}" alt="{product_name}" style="width:200px;height:200px;object-fit:cover;border-radius:8px;margin:10px 0;">\n'
        
        # ê°œì„ ëœ ìƒí’ˆ ì •ë³´ í¬ë§· (ì´ë¯¸ì§€ í¬í•¨)
        product_info = f"ã€{i}ã€‘ **{product_name}**{image_html}"
        product_info += f"ğŸ“‚ **ì¹´í…Œê³ ë¦¬**: {category}\n"
        product_info += f"ğŸ’° **ê°€ê²©**: {price:,}ì›\n"
        product_info += f"ğŸ·ï¸ **í‚¤ì›Œë“œ**: {keywords}\n"
        product_info += f"ğŸ†” **ìƒí’ˆì½”ë“œ**: {product_id}\n"
        
        products_info.append(product_info)
    
    # ê²°ê³¼ í¬ë§·íŒ…
    if products_info:
        formatted_result = f"{answer}\n\n---\n\nğŸ“š **ê´€ë ¨ ìƒí’ˆ ì •ë³´**:\n\n" + "\n\n---\n\n".join(products_info)
    else:
        formatted_result = answer
    
    return formatted_result


# ê°€ê²©ëŒ€ë³„ ìƒí’ˆ ë¶„í¬ ì‹œê°í™” í•¨ìˆ˜
def create_price_distribution_chart(search_results):
    """ê²€ìƒ‰ ê²°ê³¼ì˜ ê°€ê²© ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    try:
        # ê°€ê²© ë°ì´í„° ì¶”ì¶œ
        prices = [doc.metadata.get('ê°€ê²©', 0) for doc in search_results]
        if not prices:
            return None
            
        # ê°€ê²©ëŒ€ êµ¬ê°„ ì„¤ì •
        price_ranges = [0, 10000, 30000, 50000, 100000, 200000, float('inf')]
        labels = ['1ë§Œì› ì´í•˜', '1~3ë§Œì›', '3~5ë§Œì›', '5~10ë§Œì›', '10~20ë§Œì›', '20ë§Œì› ì´ìƒ']
        
        # ê°€ê²©ëŒ€ë³„ ìƒí’ˆ ê°œìˆ˜ ê³„ì‚°
        counts = [0] * len(labels)
        for price in prices:
            for i, (lower, upper) in enumerate(zip(price_ranges[:-1], price_ranges[1:])):
                if lower <= price < upper:
                    counts[i] += 1
                    break
        
        # ì°¨íŠ¸ ìƒì„±
        plt.figure(figsize=(8, 5))
        plt.bar(labels, counts, color='skyblue')
        plt.xlabel('ê°€ê²©ëŒ€')
        plt.ylabel('ìƒí’ˆ ìˆ˜')
        plt.title('ê²€ìƒ‰ ê²°ê³¼ ê°€ê²© ë¶„í¬')
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ ë²„í¼ë¡œ ì €ì¥
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_str = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
        return f"<img src='data:image/png;base64,{img_str}' alt='ê°€ê²© ë¶„í¬ ì°¨íŠ¸'>"
    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì‹œê°í™” í•¨ìˆ˜
def create_category_distribution_chart(search_results):
    """ê²€ìƒ‰ ê²°ê³¼ì˜ ì¹´í…Œê³ ë¦¬ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    try:
        # ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì¶”ì¶œ
        categories = {}
        for doc in search_results:
            category = doc.metadata.get('ì¹´í…Œê³ ë¦¬ëª…', '').split(' > ')[0]
            if category:
                categories[category] = categories.get(category, 0) + 1
        
        if not categories:
            return None
            
        # ìƒìœ„ 5ê°œ ì¹´í…Œê³ ë¦¬ë§Œ ì„ íƒ
        top_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # ì°¨íŠ¸ ìƒì„±
        plt.figure(figsize=(8, 5))
        plt.bar([cat for cat, count in top_categories], [count for cat, count in top_categories], color='lightgreen')
        plt.xlabel('ì¹´í…Œê³ ë¦¬')
        plt.ylabel('ìƒí’ˆ ìˆ˜')
        plt.title('ê²€ìƒ‰ ê²°ê³¼ ì¹´í…Œê³ ë¦¬ ë¶„í¬')
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ ë²„í¼ë¡œ ì €ì¥
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_str = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
        return f"<img src='data:image/png;base64,{img_str}' alt='ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì°¨íŠ¸'>"
    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ë°ëª¨ ëª¨ë“œ ì—¬ë¶€ í™•ì¸
def check_demo_mode(file_path="narosu_db.csv", embeddings_dir="embeddings"):
    """ë°ëª¨ ëª¨ë“œ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤."""
    data_exists = os.path.exists(file_path)
    embeddings_exist = os.path.exists(embeddings_dir) and os.listdir(embeddings_dir) if os.path.exists(embeddings_dir) else False
    
    if not data_exists or not embeddings_exist:
        logger.warning("ì‹¤ì œ ë°ì´í„° ë˜ëŠ” ì„ë² ë”©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        return True
    
    return False


# ë°ëª¨ ëª¨ë“œ ì—¬ë¶€ í™•ì¸
def check_demo_mode(file_path="narosu_db_final.csv", embeddings_dir="embeddings_checkpoints"):
    """ë°ëª¨ ëª¨ë“œ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤."""
    data_exists = os.path.exists(file_path)
    embeddings_exist = False
    
    # ì„ë² ë”© íŒŒì¼ í™•ì¸
    if os.path.exists(embeddings_dir):
        # embeddings_checkpoint.pkl íŒŒì¼ í™•ì¸
        checkpoint_file = os.path.join(embeddings_dir, "embeddings_checkpoint.pkl")
        if os.path.exists(checkpoint_file):
            embeddings_exist = True
    
    if not data_exists:
        logger.warning(f"ë°ì´í„° íŒŒì¼ '{file_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if not embeddings_exist:
        logger.warning(f"ì„ë² ë”© íŒŒì¼ì„ '{embeddings_dir}'ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if not data_exists or not embeddings_exist:
        logger.warning("ì‹¤ì œ ë°ì´í„° ë˜ëŠ” ì„ë² ë”©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        return True
    
    return False


# ì‚¬ìš©ì ì¿¼ë¦¬ ì „ì²˜ë¦¬
def preprocess_query(query):
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = ["ì¢€", "ê·¸ëƒ¥", "ì¼ë‹¨", "ê·¸ë¦¬ê³ ", "ê·¸ë˜ì„œ", "ê·¸ëŸ¼", "ìš”", "í˜¹ì‹œ"]
    query_words = query.split()
    filtered_words = [word for word in query_words if word not in stopwords]
    
    # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
    clean_query = re.sub(r'[^\w\sê°€-í£]', ' ', ' '.join(filtered_words))
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    clean_query = re.sub(r'\s+', ' ', clean_query).strip()
    
    return clean_query

# ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥
def expand_search_query(query):
    """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤."""
    expanded_queries = [query]
    
    # ê°€ê²© ê´€ë ¨ ì¿¼ë¦¬ í™•ì¥
    price_patterns = {
        r'(\d+)ë§Œì›\s*(ì´í•˜|ë¯¸ë§Œ|ì´í•˜ì˜)': lambda m: f"{m.group(1)}ë§Œì› ì´í•˜",
        r'(\d+)ë§Œì›\s*(ì´ìƒ|ì´ˆê³¼|ì´ìƒì˜)': lambda m: f"{m.group(1)}ë§Œì› ì´ìƒ",
        r'(\d+)ë§Œì›ëŒ€': lambda m: f"{m.group(1)}ë§Œì›ëŒ€"
    }
    
    for pattern, replacement_func in price_patterns.items():
        match = re.search(pattern, query)
        if match:
            expanded_query = replacement_func(match)
            if expanded_query not in expanded_queries:
                expanded_queries.append(expanded_query)
    
    # ê³„ì ˆ ê´€ë ¨ ì¿¼ë¦¬ í™•ì¥
    season_map = {
        "ë´„": ["ë´„", "ìŠ¤í”„ë§", "3ì›”", "4ì›”", "5ì›”"],
        "ì—¬ë¦„": ["ì—¬ë¦„", "ì„œë¨¸", "6ì›”", "7ì›”", "8ì›”"],
        "ê°€ì„": ["ê°€ì„", "ì˜¤í† ë‹", "9ì›”", "10ì›”", "11ì›”"],
        "ê²¨ìš¸": ["ê²¨ìš¸", "ìœˆí„°", "12ì›”", "1ì›”", "2ì›”"]
    }
    
    for season, synonyms in season_map.items():
        if season in query:
            for synonym in synonyms:
                if synonym != season and synonym not in query:
                    new_query = query.replace(season, synonym)
                    if new_query not in expanded_queries:
                        expanded_queries.append(new_query)
    
    # ìƒí’ˆ ìœ í˜• í™•ì¥
    product_map = {
        "ìì¼“": ["ìì¼“", "ì½”íŠ¸", "ì•„ìš°í„°"],
        "ê°€ë°©": ["ê°€ë°©", "ë°±", "í´ëŸ¬ì¹˜", "í† íŠ¸ë°±", "ìˆ„ë”ë°±"],
        "ì‹ ë°œ": ["ì‹ ë°œ", "ìŠˆì¦ˆ", "ìš´ë™í™”", "ìŠ¤ë‹ˆì»¤ì¦ˆ"]
    }
    
    for product, synonyms in product_map.items():
        if product in query:
            for synonym in synonyms:
                if synonym != product and synonym not in query:
                    new_query = query.replace(product, synonym)
                    if new_query not in expanded_queries:
                        expanded_queries.append(new_query)
    
    return expanded_queries[:3]  # ìµœëŒ€ 3ê°œ ì¿¼ë¦¬ë¡œ ì œí•œ

# ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_rag_system():
    """RAG ì‹œìŠ¤í…œì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embeddings_model = get_embeddings()
    if embeddings_model is None:
        logger.error("ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    data_file = "narosu_db_final.csv"
    excel_file = "narosu_db_final.xlsx"
    embeddings_dir = "embeddings_checkpoints"
    
    # ë°ëª¨ ëª¨ë“œ í™•ì¸
    demo_mode = check_demo_mode(file_path=data_file, embeddings_dir=embeddings_dir)
    

    # ìƒí’ˆ ë°ì´í„° ë¡œë“œ
    product_data = load_product_data(file_path=data_file, excel_path=excel_file)
    
    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    collection_name = "product_recommendations"
    qdrant_client = setup_qdrant_client(collection_name)
    
    # ì„ë² ë”© ë°ì´í„° ë¡œë“œ
    embeddings_data, product_ids = load_embeddings(embeddings_dir=embeddings_dir)
    

    else:
        # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        vector_store = init_vector_store(qdrant_client, collection_name, product_data, embeddings_data, product_ids, embeddings_model)
    
    # LLM ì´ˆê¸°í™”
    llm = init_llm()
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    if vector_store is not None and llm is not None:
        rag_pipeline = init_rag_pipeline(vector_store, llm)
    else:
        logger.error("ë²¡í„° ì €ì¥ì†Œ ë˜ëŠ” LLMì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        rag_pipeline = None
    
    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    chat_history = ChatHistory()
    
    if rag_pipeline is not None:
        logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    else:
        logger.error("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨!")
    
    return rag_pipeline, chat_history, vector_store

# ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(message, rag_pipeline, chat_history, vector_store):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not message:
        return "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if rag_pipeline is None:
        return "RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
    
    try:
        # ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
        chat_history.add_message("user", message)
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        clean_query = preprocess_query(message)
        
        # ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œ
        naver_products = search_naver_shopping(clean_query)
        formatted_naver_products = format_naver_products(naver_products)
        
        # RAG ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
        prompt = chat_history.format_prompt(clean_query)
        result = rag_pipeline({"query": clean_query})
        
        # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
        chat_history.add_search_result(clean_query, result.get('source_documents', []))
        
        # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
        response = format_search_results(result)
        
        # ë„¤ì´ë²„ ì‡¼í•‘ ê²°ê³¼ ì¶”ê°€
        if formatted_naver_products:
            response += "\n\nğŸ“¦ ë„¤ì´ë²„ ì‡¼í•‘ ì¶”ì²œ ìƒí’ˆ:\n\n" + "\n\n".join(formatted_naver_products)
        
        # ìƒí’ˆ ê°€ê²© ë¶„í¬ ì°¨íŠ¸ ìƒì„± (ì¡°ê±´ë¶€)
        if "ê°€ê²©" in message.lower() or "ì–¼ë§ˆ" in message.lower():
            price_chart = create_price_distribution_chart(result.get('source_documents', []))
            if price_chart:
                response += f"\n\n### ê²€ìƒ‰ ê²°ê³¼ ê°€ê²© ë¶„í¬\n{price_chart}"
        
        # ì‘ë‹µì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
        chat_history.add_message("assistant", response)
        
        return response
    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {str(e)}"
        chat_history.add_message("assistant", error_msg)
        return error_msg
    
    
# ê²€ìƒ‰ í†µê³„ ì‹œê°í™” í•¨ìˆ˜
def create_search_analytics(chat_history):
    """ê²€ìƒ‰ í†µê³„ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    analytics = chat_history.get_search_analytics()
    
    if isinstance(analytics, str):
        return analytics
    
    # ê²€ìƒ‰ í†µê³„ í¬ë§·íŒ…
    result = "## ğŸ” ê²€ìƒ‰ í†µê³„\n\n"
    result += f"ì´ ê²€ìƒ‰ íšŸìˆ˜: {analytics['total_searches']}íšŒ\n\n"
    
    if analytics['top_categories']:
        result += "### ì¸ê¸° ì¹´í…Œê³ ë¦¬:\n"
        for i, (category, count) in enumerate(analytics['top_categories'][:5], 1):
            result += f"{i}. {category}: {count}íšŒ\n"
        result += "\n"
    
    if analytics['search_queries']:
        result += "### ìµœê·¼ ê²€ìƒ‰ì–´:\n"
        recent_queries = analytics['search_queries'][-5:]  # ìµœê·¼ 5ê°œ ê²€ìƒ‰ì–´
        for i, query in enumerate(recent_queries, 1):
            result += f"{i}. {query}\n"
    
    return result

import urllib.request
import json

def search_naver_shopping(query, display=2):
    """ë„¤ì´ë²„ ì‡¼í•‘ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        client_id = "AQncjiAhGcWf0WegURyt"
        client_secret = "XFVLBoNQxM"
        
        # ê²€ìƒ‰ì–´ ì¸ì½”ë”©
        encoded_query = urllib.parse.quote(query)
        url = f"https://openapi.naver.com/v1/search/shop.json?query={encoded_query}&display={display}&sort=sim"
        
        # API ìš”ì²­ ìƒì„±
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        
        # API í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
        response = urllib.request.urlopen(request)
        response_code = response.getcode()
        
        if response_code == 200:
            response_body = response.read()
            response_data = json.loads(response_body.decode('utf-8'))
            return response_data.get('items', [])
        else:
            logger.error(f"ë„¤ì´ë²„ API ìš”ì²­ ì‹¤íŒ¨: ì‘ë‹µ ì½”ë“œ {response_code}")
            return []
    except Exception as e:
        logger.error(f"ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def format_naver_products(products):
    """ë„¤ì´ë²„ ì‡¼í•‘ API ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    formatted_products = []
    
    for i, product in enumerate(products, 1):
        title = product.get('title', '').replace('<b>', '').replace('</b>', '')
        price = int(product.get('lprice', '0'))
        mall_name = product.get('mallName', 'ì•Œ ìˆ˜ ì—†ìŒ')
        product_id = product.get('productId', '')
        product_type = product.get('productType', '')
        link = product.get('link', '')
        image = product.get('image', '')
        category = product.get('category1', '') + ' > ' + product.get('category2', '')
        
        product_info = f"ã€ë„¤ì´ë²„ ì¶”ì²œ {i}ã€‘ {title}\n"
        product_info += f"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category}\n"
        product_info += f"   ğŸ’° ê°€ê²©: {price:,}ì›\n"
        product_info += f"   ğŸ¬ íŒë§¤ì²˜: {mall_name}\n"
        product_info += f"   ğŸ”— ë§í¬: {link}\n"
        
        formatted_products.append(product_info)
    
    return formatted_products


# respond í•¨ìˆ˜ (ì˜ˆì‹œ ì§ˆë¬¸ íŠ¹ë³„ ì²˜ë¦¬)
def respond(message, history):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if message.strip() == "":
        return "", history
    
    
    # íŠ¹ìˆ˜ ëª…ë ¹ì–´ ì²˜ë¦¬
    if message.strip() == "/í†µê³„":
        try:
            stats = create_search_analytics(chat_history)
            history.append((message, stats))
            return "", history
        except Exception as e:
            error_msg = f"í†µê³„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            history.append((message, error_msg))
            return "", history
    
    # ì¼ë°˜ ì‘ë‹µ ìƒì„±
    try:
        if rag_pipeline is None:
            error_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            history.append((message, error_msg))
        else:
            # ì±„íŒ… ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            chat_history.add_message("user", message)
            
            # ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° RAG ê²€ìƒ‰
            clean_query = preprocess_query(message)
            result = rag_pipeline({"query": clean_query})
            
            # ê²°ê³¼ í¬ë§·íŒ… (ì´ë¯¸ì§€ í¬í•¨)
            response = format_search_results(result)
            
            # ì±„íŒ… ê¸°ë¡ì— ì‘ë‹µ ì¶”ê°€
            chat_history.add_message("assistant", response)
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            history.append((message, response))
        
        return "", history
    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        history.append((message, error_msg))
        return "", history
    

def create_gradio_interface():
    """Gradio ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë¡œê¹…
    current_dir = os.getcwd()
    logger.info(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {current_dir}")
    
    data_file = "narosu_db_final.csv"
    excel_file = "narosu_db_final.xlsx"
    embeddings_dir = "embeddings_checkpoints"
    checkpoint_file = os.path.join(embeddings_dir, "embeddings_checkpoint.pkl")
    
    logger.info(f"CSV íŒŒì¼ ê²½ë¡œ: {os.path.join(current_dir, data_file)}, ì¡´ì¬ ì—¬ë¶€: {os.path.exists(data_file)}")
    logger.info(f"Excel íŒŒì¼ ê²½ë¡œ: {os.path.join(current_dir, excel_file)}, ì¡´ì¬ ì—¬ë¶€: {os.path.exists(excel_file)}")
    logger.info(f"ì„ë² ë”© ë””ë ‰í† ë¦¬: {os.path.join(current_dir, embeddings_dir)}, ì¡´ì¬ ì—¬ë¶€: {os.path.exists(embeddings_dir)}")
    logger.info(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼: {os.path.join(current_dir, checkpoint_file)}, ì¡´ì¬ ì—¬ë¶€: {os.path.exists(checkpoint_file)}")
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    global rag_pipeline, chat_history, vector_store
    rag_pipeline, chat_history, vector_store = initialize_rag_system()
    
    # ì¸í„°í˜ì´ìŠ¤ ìƒì„±
    with gr.Blocks(css="footer {visibility: hidden}") as interface:
        gr.Markdown("# ğŸ›ï¸ ìŠ¤ë§ˆíŠ¸ ìƒí’ˆ ê²€ìƒ‰ ì–´ì‹œìŠ¤í„´íŠ¸")
        gr.Markdown("ìƒí’ˆì— ê´€í•œ ì§ˆë¬¸ì´ë‚˜ ì¶”ì²œì„ ìš”ì²­í•´ë³´ì„¸ìš”. ì•„ë˜ ì˜ˆì‹œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        
        chatbot = gr.Chatbot(
            height=500,
            bubble_full_width=False,
            show_label=False,
            show_copy_button=True,
            layout="panel"
        )
        
        with gr.Row():
            msg = gr.Textbox(
                placeholder="ìƒí’ˆì— ê´€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”...",
                scale=9,
                show_label=False,
                container=False
            )
            submit = gr.Button("ì „ì†¡", scale=1, variant="primary")
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ì„¹ì…˜ ì¶”ê°€
        gr.Markdown("## ğŸ’¡ ë°”ë¡œ ì‚¬ìš©í•´ë³¼ ìˆ˜ ìˆëŠ” ì˜ˆì‹œ ì§ˆë¬¸")
        
        with gr.Row():
            example_btn1 = gr.Button("ì—¬ì„±ìš© ê°€ì„ ìì¼“ ì¶”ì²œí•´ì¤˜", scale=1)
            example_btn2 = gr.Button("2ë§Œì› ì´í•˜ì˜ ì£¼ë°©ìš©í’ˆ ì•Œë ¤ì¤˜", scale=1)
            example_btn3 = gr.Button("ì•„ì´í° 15 ì¼€ì´ìŠ¤ ì¶”ì²œ", scale=1)
        
        with gr.Row():
            example_btn4 = gr.Button("ê²€ì€ìƒ‰ í¬ë¡œìŠ¤ë°± ì¶”ì²œí•´ì¤˜", scale=1)
            example_btn5 = gr.Button("ìš”ì¦˜ íŠ¸ë Œë“œ íŒ¨ì…˜ ì•„ì´í…œì€?", scale=1)
            example_btn6 = gr.Button("/í†µê³„", scale=1)
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ë§
        submit.click(respond, [msg, chatbot], [msg, chatbot])
        msg.submit(respond, [msg, chatbot], [msg, chatbot])
        
        # ì˜ˆì‹œ ë²„íŠ¼ì— ì´ë²¤íŠ¸ ì—°ê²°
        example_btn1.click(lambda: "ì—¬ì„±ìš© ê°€ì„ ìì¼“ ì¶”ì²œí•´ì¤˜", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        example_btn2.click(lambda: "2ë§Œì› ì´í•˜ì˜ ì£¼ë°©ìš©í’ˆ ì•Œë ¤ì¤˜", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        example_btn3.click(lambda: "ì•„ì´í° 15 ì¼€ì´ìŠ¤ ì¶”ì²œ", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        example_btn4.click(lambda: "ê²€ì€ìƒ‰ í¬ë¡œìŠ¤ë°± ì¶”ì²œí•´ì¤˜", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        example_btn5.click(lambda: "ìš”ì¦˜ íŠ¸ë Œë“œ íŒ¨ì…˜ ì•„ì´í…œì€?", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        example_btn6.click(lambda: "/í†µê³„", None, msg).then(
            respond, [msg, chatbot], [msg, chatbot]
        )
        
        # ì¶”ê°€ ì •ë³´ ì„¹ì…˜
        with gr.Accordion("ë„ì›€ë§ ë° ì¶”ê°€ ì˜ˆì‹œ ì§ˆë¬¸", open=False):
            gr.Markdown("""
            ### ğŸ” ì´ëŸ° ì§ˆë¬¸ë„ ë¬¼ì–´ë³´ì„¸ìš”:
            
            - ê°€ì„ìš© ì—¬ì„± ìì¼“ ì¤‘ì— ê°€ì¥ ì¸ê¸°ìˆëŠ” ê²ƒì€?
            - 5ë§Œì› ì´í•˜ì˜ ì„ ë¬¼ìš© ì£¼ë°©ìš©í’ˆ ì¶”ì²œí•´ì¤˜
            - ìºì£¼ì–¼í•œ ìŠ¤íƒ€ì¼ì˜ ë‚¨ì„± ì˜ë¥˜ ì•Œë ¤ì¤˜
            - ê²¨ìš¸ì²  ë”°ëœ»í•œ ì˜ë¥˜ ì¶”ì²œí•´ì£¼ì„¸ìš”
            - ê°€ì„±ë¹„ ì¢‹ì€ ì£¼ë°© ìš©í’ˆì€?
            - ë””ì§€í„¸ ì œí’ˆ ì¤‘ ì¸ê¸° ìˆëŠ” ê²ƒ
            
            ### ğŸ’¡ ëª…ë ¹ì–´ ì•ˆë‚´
            - **/í†µê³„**: ê²€ìƒ‰ í†µê³„ í™•ì¸í•˜ê¸°
            
            ### ğŸ›ï¸ ìƒí’ˆ ê²€ìƒ‰ íŒ
            - ê°€ê²©ëŒ€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - ìƒ‰ìƒ, ìŠ¤íƒ€ì¼, ìš©ë„ ë“± êµ¬ì²´ì ì¸ ì¡°ê±´ì„ í¬í•¨í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤
            - ê³„ì ˆ, ì—°ë ¹ëŒ€ ë“±ì„ ëª…ì‹œí•˜ë©´ ë§ì¶¤í˜• ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤
            """)
    
    return interface



# ë©”ì¸ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ í•¨ìˆ˜"""
    interface = create_gradio_interface()
    interface.launch(share=True)

if __name__ == "__main__":
    main()